; Environments
%include common-env.drake

BASE=download

;;
; Methods
;;

file() [eval]
  echo "$CODE" | tee $OUTPUT | nl

download()
  for f in $INPUTS; do 
    source $f
    if [ -z "$DIR" -o -z "$URL" ]; then
      echo "params are not set. DIR=$DIR, URL=$URL"
    else 
      if [ -d "$DIR" ]; then
        echo "The directory exists. Skip. DIR=$DIR, URL=$URL"
      else
        mkdir -p $DIR
        if [ "${URL##*.}" == "zip" ]; then
          echo "Download a file into $DIR from URL: $URL ..."
          TMP_FILE="tmp.`basename $f`.zip"
          wget -qO- -O "$TMP_FILE" $URL && unzip -d "$DIR/" $TMP_FILE && rm $TMP_FILE
        else
          echo "Download a file into $DIR/`basename $URL` from URL: $URL ..."
          wget -O "$DIR/`basename $URL`" $URL
        fi
      fi
    fi
  done

;;
; downlaod data
;;

; splunk tutorial data: http://docs.splunk.com/Documentation/Splunk/6.2.1/PivotTutorial/GetthetutorialdataintoSplunk#Download_the_sample_data_file
splunk-env.sh <- [method:file method-mode:append]
  DIR=$[DATA_DIR_LOCAL]/splunk
  URL=http://docs.splunk.com/images/Tutorial/tutorialdata.zip

; pig tutorial data
excite-env.sh <- [method:file method-mode:append]
  DIR=$[DATA_DIR_LOCAL]/excite
  URL=https://raw.githubusercontent.com/apache/pig/release-0.14.0/tutorial/data/excite-small.log

splunk <- splunk-env.sh [method:download method-mode:append]
excite <- excite-env.sh [method:download method-mode:append]

%download_all <- splunk-env.sh, excite-env.sh [method:download method-mode:append]

; hdfs upload
%upload <- %download_all
  $[HDFS_EXEC] dfs -test -d $[DATA_DIR_HDFS]
  if [ "$?" -eq "0" ]; then
    echo "The path exists. Remove it first with the commmand:"
    echo $[HDFS_EXEC] dfs -rmr $[DATA_DIR_HDFS]
  else
    $[HDFS_EXEC] dfs -mkdir $[ROOT_DIR_HDFS]/
    $[HDFS_EXEC] dfs -copyFromLocal $[DATA_DIR_LOCAL] $[DATA_DIR_HDFS]
    echo "Uploaded from local path $[DATA_DIR_LOCAL] to hdfs path $[DATA_DIR_HDFS]"
  fi

